## ML Course

* TOC
{:toc}

## Teaching Staff:

Lectures: Gal Chechik, gondaneuralnetworks @ gmail.com

TA: Shauli Ravfogel, shauli321 @ gmail.com

Home assignment grading: Hodaya Koslovski, nn.homework.2019 @ gmail.com

When and where: 
- Gonda center (Bldg #901), Room 102 ("The small room")
- Mon. 10:00-11:30 (Gal) 
- Mon. 16:00-17:30 (Shauli)   
- Tue. 10:00-11:30 (Gal)   

**The course covers**: 
Theory and algorithms of learning from examples, with a focus on deep learning. 
There will also be a short chapter on information theory and its relation to learning.

- Part A: Learning from Examples ([textbook 1](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738), [online course](https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA))

- Part B: Information processing, plasticity and unsupervised Learning:
Neurons extract structures from stochastic signals ([textbook 1](http://www.cs.toronto.edu/~mackay/itprnn/p0.html#book.html), [textbook 2](http://books.google.de/books?id=hrZYAAAACAAJ&dq=theoretical+neuroscience))

- Part C: Dynamical systems ([textbook 1](http://www.google.com/url?q=http%3A%2F%2Fwww.ams.jhu.edu%2F~ers%2Finvite%2Findex.html&sa=D&sntz=1&usg=AFQjCNHx49RlyhRwAxnU3GmmWUNv7pOjmw), [textbook 2](http://www.google.com/url?q=http%3A%2F%2Fwww.izhikevich.org%2Fpublications%2Fdsn.pdf&sa=D&sntz=1&usg=AFQjCNEeryHZ46ulsyTDZDfGxbpK5eH5AQ))


**List of classes Fall 2020**: [Insert a link here](https://)




## Home Assignments 

- Instructions

    1. To appear on our lists, make sure to send an email with the subject line  NN2020 to gondaneuralnetworks @ gmail.com . 
    2. Submission deadlines are given below as well on the course plan on the home page. 
    3. To submit, scan and email your assignment to nn.homework.2020 @ gmail.com. Alternatively, you can submit a hard copy to Hodaya located at the Slovin's lab, 2nd floor.
    4. FAQ: [Why use python over matlab?](https://www.google.com/url?q=https%3A%2F%2Finsights.stackoverflow.com%2Ftrends%3Ftags%3Dpython%252Cmatlab&sa=D&sntz=1&usg=AFQjCNFnW1cNIYgh1evWBq3Pg3IukNgG7w)

- Grades

- Assignments

| Submission deadline  | Files |
| ------------- | ------------- |
| date  | [EX 1]()  |
| date2  | [EX 2]()  |




## Notes and links

### Slides from Tirgul (Shauli, 2020):
- [Class 1](https://docs.google.com/presentation/d/1wRg0xAyZ2ASUtwKPpzP5Kazyb_y_1Id6c90conArPAA/edit?usp=sharing): Introduction, projections, GD, Newton method
- [Class 2](https://docs.google.com/presentation/d/1QrbO8eYUXvAK5sT0xBsmN3SIYHX_O0Y9iX1lGdOWeOk/edit?usp=sharing): MLE, Logistic regression, colab
- [Class 3](https://docs.google.com/presentation/d/1UBFjQ-CRioD4RjI_d81ahWgFdSyxuR6r437nH5c21Uc/edit?usp=sharing): Multiclass, MLPs, backprop
- [Class 4](https://docs.google.com/presentation/d/1fg7OyTcDFR0M2ha4QKTL2qfBtkf_27MCAWD-y1HZhr8/edit?usp=sharing): SVMs, Deep Dream
- [Class 5](https://docs.google.com/presentation/d/12R-nIc4jGd0PJaORHD8SkUjBj2yeBnwT52afELfTQaI/edit?usp=sharing): Multivariate Gaussians, PCA
- Class 6: [Information Theory](https://docs.google.com/presentation/d/1HdDItP2EbgmHUA939Z-wyS45ScNN89NB9J5G5WI0QkE/edit?usp=sharing), [Yoav Goldberg's Attention slides](http://www.google.com/url?q=http%3A%2F%2Fu.cs.biu.ac.il%2F~89-687%2Flec11.pdf&sa=D&sntz=1&usg=AFQjCNEVrtTDxxebNTqGW8QtmUFfQol78g)
- [Class 7](https://docs.google.com/presentation/d/1buQ_iqUogPq_YQJAS6pQNvHdQAAqWekcjzOJBEtl1Bs/edit?usp=sharing): Source coding
- [Class 8](https://docs.google.com/presentation/d/1nH1WiHHv3AcagOF4l2F85bKRchRgKGJd_I6TZrmbigw/edit?usp=sharing): Autoencoders
- Class 9: [AEP](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxnb25kYW5ldXJhbG5ldHdvcmtzfGd4OjQ1NWNiMzRmYWQ2YjdkMmY), [Differential Entropy](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxnb25kYW5ldXJhbG5ldHdvcmtzfGd4OjE2NmNhZjEzZGYwZjdlZA)
- [Class 10](https://docs.google.com/presentation/d/1PalysOogCCyk7V2RheMtT0PA0_mZFa5EE1fSSVPN3W0/edit?usp=sharing): VAE       



### Topics: 

- Deep Neural Networks: NN
- Dynamical systems: DS
- Machine Learning: ML
- Probabilistic modelling, information theory: PR / IT
- Theoretical Neuroscience: TH
    
    
### Exams from previous years: 


Exams from previous years: 

- 2008 [Exam I](https://sites.google.com/site/gondaneuralnetworks/Neural-networks-fall-2008-final-exam-I.pdf?attredirects=0), [Exam II](https://sites.google.com/site/gondaneuralnetworks/Neural-networks-fall-2008-final-exam-II.pdf?attredirects=0)
- 2009 [Exam I](https://sites.google.com/site/gondaneuralnetworks/Neural-networks-fall-2009-final-exam-I.pdf?attredirects=0), [Exam II](https://sites.google.com/site/gondaneuralnetworks/Neural-networks-fall-2009-final-exam-II.pdf?attredirects=0)
- 2010 [Exam I](https://sites.google.com/site/gondaneuralnetworks/Fall2010_MOED-A.pdf?attredirects=0), [Exam II](https://sites.google.com/site/gondaneuralnetworks/Fall2010_MOED-B.pdf?attredirects=0) 
- 2011 [Exam I](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxnb25kYW5ldXJhbG5ldHdvcmtzfGd4OjUzOTE2ZDI4MTE4YjFjMDY), [Exam II](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxnb25kYW5ldXJhbG5ldHdvcmtzfGd4Ojc5NjY1NGQ3NThkNGY2ODE), [mid-term A](https://sites.google.com/site/gondaneuralnetworks/NN-2011-midterm-exam-moed-A.pdf?attredirects=0), [mid-term B](https://sites.google.com/site/gondaneuralnetworks/NN-2011-midterm-exam-moed-B.pdf?attredirects=0)
- 2012 [Exam I](https://sites.google.com/site/gondaneuralnetworks/NN-2012-final-exam-moed-A-final.pdf?attredirects=0), [Exam II](https://sites.google.com/site/gondaneuralnetworks/NN-2012-final-exam-moed-B.pdf?attredirects=0), , [mid-term A](https://sites.google.com/site/gondaneuralnetworks/NN-2012-midterm-exam-moed-A.pdf?attredirects=0), [mid-term B](https://sites.google.com/site/gondaneuralnetworks/NN-2012-midterm-exam-moed-B.pdf?attredirects=0),
- 2013 [Exam I](https://sites.google.com/site/gondaneuralnetworks/NN-2013-mid-term-exam-moed-B.pdf), [Exam I](https://sites.google.com/site/gondaneuralnetworks/NN-2013-final-exam-moed-B.pdf?attredirects=0)
- 2014 [Final Exam](https://sites.google.com/site/gondaneuralnetworks/NN-2014-final-exam-moed-A.pdf?attredirects=0), [Midterm Exam](https://sites.google.com/site/gondaneuralnetworks/NN-2014-midterm-exam-moed-A.pdf?attredirects=0)
- 2014 [Sample problems for the mid-term exam](https://sites.google.com/site/gondaneuralnetworks/home/rehearsal), and the [final exam](https://sites.google.com/site/gondaneuralnetworks/Fall2012_rehearse_problemset.pdf?attredirects=0)
- 2015 course was not given
- 2016 [Exam I](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxnb25kYW5ldXJhbG5ldHdvcmtzfGd4OjNkOWU0ZjI0Y2FjYmU4NTU),  [Exam II](https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxnb25kYW5ldXJhbG5ldHdvcmtzfGd4OjFmNDcxZWY2OTg5YThjMGE)
- 2017 course was not given
- 2018 course was not given

### Related material:

- NN: [Attractor neural networks](http://www.scholarpedia.org/article/Attractor_network) (Scholarpedia)
- TH: [Conductance based models](http://www.scholarpedia.org/article/Conductance-based_models) (Scholarpedia)
- TH: Fitzhugh-Naumo model: [Scholarpedia (with animated GIFs)](http://www.scholarpedia.org/article/FitzHugh-Nagumo_model), [Book chapters by Izhikevitch](http://www.izhikevich.org/publications/dsn.pdf)
- DS: Lyapunov [as energy functions](http://hebb.mit.edu/courses/9.641/2006/readings/Slotine91.pdf)
- ML: Bell & Sejnowski's paper: ["An information-maximization approach to blind separation and blind deconvolution"](http://web.mit.edu/6.962/www/www_spring_2001/shaas/bell.blind.pdf)



## Administration 

**The final grade **is computed as a combination of (1) home assignments (2) Mid-term exam (3) Final project. Students must complete all three to pass the course. The two home assignments with the lowest grades will not be taken into account (if their grade is higher than 60).

                             Grade = 0.3 * Home Assignments + 0.3 Mid-term exam + 0.4 Final project.

**Home assignment policies**: Students are allowed to solve assignments in pairs. They must write the solutions themselves and submit each assignment as individuals. If you have collaborated when working on an assignment, mark clearly the name of the people you collaborated with. 

**Programming exercises**: 

Each student should submit a digital copy of their exercise.
It should contain: 

1. (full answers and detailed explanation as you were asked to provide in the home assignment.
2. your code.

- submission: 
Email it to:  nn.homework.2020 @ gmail.com  by the deadline.

Acceptable formats are: PDF, plain text, or  word.

The email title should include #assignment, and the submitting students full name and ID.

For example,  Email subject: "Assignment 3, submitted by Uri Shalit, ID 01234787485".

- Late home assignment submissions: 

Each student is allowed a total of 5 late days, to spend across all exercises as they wish. We cannot guarantee that exercises submitted after the deadline will be at all graded, but if they are graded, they will suffer a penalty of 20 points. 
